{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores II - Tarefa 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carregar as bases\n",
    "\n",
    "Vamos carregar as bases lidas na tarefa passada. Se você salvou essas bases em arquivo texto, basta fazer a leitura com o comando ```pd.read_csv``` das seguintes bases:\n",
    "\n",
    "- X_train\n",
    "- Y_train\n",
    "- X_test\n",
    "- Y_test\n",
    "\n",
    "Não se esqueça de considerar a leitura dos índices dos arquivos no ```read_csv()```!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\donegá\\appdata\\roaming\\python\\python311\\site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip --no-warn-script-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\donegá\\appdata\\roaming\\python\\python311\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\donegá\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\donegá\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "ERROR: Could not find a version that satisfies the requirement scikit-lear (from versions: none)\n",
      "ERROR: No matching distribution found for scikit-lear\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall scikit-lear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caminho para o diretório\n",
    "caminho = \"C:/Users/Donegá/OneDrive/Documentos/ciencia_dados/Modulo_17/UCI HAR Dataset/\"\n",
    "\n",
    "# Carregando os dados de treinamento e teste\n",
    "X_train = pd.read_csv(caminho + \"train/X_train.txt\", sep='\\s+', header=None, index_col=False)\n",
    "Y_train = pd.read_csv(caminho + \"train/y_train.txt\", header=None, index_col=False)\n",
    "X_test = pd.read_csv(caminho + \"test/X_test.txt\", sep='\\s+', header=None, index_col=False)\n",
    "Y_test = pd.read_csv(caminho + \"test/y_test.txt\", header=None, index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Divisão da base em Treino, Validação e Teste\n",
    "\n",
    "A base já se encontra dividida em Treino e Validação. O que vamos fazer então é extrair uma base de Validação da base de Treino.\n",
    "\n",
    "Extraia 25% da base de treino como base de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos dados de treino: (5514, 561) (5514, 1)\n",
      "Shape dos dados de validação: (1838, 561) (1838, 1)\n"
     ]
    }
   ],
   "source": [
    "# Dividindo a base de treino em treino e validação\n",
    "X_treino, X_validacao, Y_treino, Y_validacao = train_test_split(X_train, Y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Verificando o shape dos dados de treino e validação\n",
    "print(\"Shape dos dados de treino:\", X_treino.shape, Y_treino.shape)\n",
    "print(\"Shape dos dados de validação:\", X_validacao.shape, Y_validacao.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Melhores 3 variáveis\n",
    "\n",
    "Rode uma árvore com profundidade máxima igual a 4 para prever a atividade humana com todas as variáveis.\n",
    "Observe a importância das variáveis e considere as 3 variáveis com maior importância para os próximos passos.\n",
    "Dica: utilize o atributo ```clf.feature_importances_``` da árvore treinada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As três variáveis mais importantes são:\n",
      "     Feature  Importance\n",
      "52        52    0.283674\n",
      "389      389    0.254900\n",
      "559      559    0.166670\n"
     ]
    }
   ],
   "source": [
    "# Inicializando e treinando a árvore de decisão\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Obtendo a importância das features\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "# Criando um DataFrame para facilitar a visualização\n",
    "importances_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})\n",
    "\n",
    "# Ordenando as features pela importância em ordem decrescente\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Obtendo as três features mais importantes\n",
    "top3_features = importances_df.head(3)\n",
    "\n",
    "# Exibindo as três features mais importantes\n",
    "print(\"As três variáveis mais importantes são:\")\n",
    "print(top3_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construa uma árvore com as 3 melhores variáveis\n",
    "\n",
    "Utilizando as três variáveis encontradas acima, construa uma árvore de decisão. Encontre o melhor ```ccp_alpha``` utilizando a base de validação, conforme a estrutura que vimos em aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor ccp_alpha: 0.0\n",
      "Acurácia de validação correspondente: 0.8830250272034821\n"
     ]
    }
   ],
   "source": [
    "# Carregando as bases de dados\n",
    "caminho = \"C:/Users/Donegá/OneDrive/Documentos/ciencia_dados/Modulo_17/UCI HAR Dataset/\"\n",
    "X_train = pd.read_csv(caminho + \"train/X_train.txt\", sep='\\s+', header=None)\n",
    "X_test = pd.read_csv(caminho + \"test/X_test.txt\", sep='\\s+', header=None)\n",
    "y_train = pd.read_csv(caminho + \"train/y_train.txt\", header=None)\n",
    "y_test = pd.read_csv(caminho + \"test/y_test.txt\", header=None)\n",
    "\n",
    "# Dividindo a base de treino em treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Selecionando as três variáveis mais importantes\n",
    "important_features = [52, 389, 559]\n",
    "\n",
    "# Selecionando apenas as três variáveis mais importantes\n",
    "X_train_subset = X_train.iloc[:, important_features]\n",
    "X_val_subset = X_val.iloc[:, important_features]\n",
    "\n",
    "# Criando uma lista de valores ccp_alpha\n",
    "ccp_alphas = np.linspace(0, 0.05, 50)\n",
    "\n",
    "# Inicializando listas para armazenar os resultados\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Treinando uma árvore de decisão para cada valor de ccp_alpha\n",
    "for alpha in ccp_alphas:\n",
    "    # Criando e ajustando o modelo de árvore de decisão\n",
    "    clf = DecisionTreeClassifier(ccp_alpha=alpha, random_state=42)\n",
    "    clf.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Fazendo previsões na base de treino e base de validação\n",
    "    train_preds = clf.predict(X_train_subset)\n",
    "    val_preds = clf.predict(X_val_subset)\n",
    "    \n",
    "    # Calculando a acurácia na base de treino e base de validação\n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    val_accuracy = accuracy_score(y_val, val_preds)\n",
    "    \n",
    "    # Adicionando as acurácias às listas\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "# Encontrando o índice do melhor ccp_alpha com base na acurácia de validação\n",
    "best_alpha_idx = np.argmax(val_accuracies)\n",
    "best_alpha = ccp_alphas[best_alpha_idx]\n",
    "\n",
    "# Mostrando o melhor ccp_alpha e sua acurácia de validação correspondente\n",
    "print(\"Melhor ccp_alpha:\", best_alpha)\n",
    "print(\"Acurácia de validação correspondente:\", val_accuracies[best_alpha_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Avaliação do modelo\n",
    "\n",
    "Avalie a árvore encontrada no item anterior na base de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia na base de testes: 0.6942653545978962\n"
     ]
    }
   ],
   "source": [
    "# Criando e ajustando a árvore de decisão com o melhor ccp_alpha encontrado\n",
    "best_clf = DecisionTreeClassifier(ccp_alpha=best_alpha, random_state=42)\n",
    "best_clf.fit(X_train_subset, y_train)\n",
    "\n",
    "# Fazendo previsões na base de testes\n",
    "test_preds = best_clf.predict(X_test.iloc[:, important_features])\n",
    "\n",
    "# Calculando a acurácia na base de testes\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "# Mostrando a acurácia na base de testes\n",
    "print(\"Acurácia na base de testes:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
