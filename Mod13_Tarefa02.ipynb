{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from seaborn import load_dataset\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,  StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   id_cliente             15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12427 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  renda                  15000 non-null  float64\n",
      "dtypes: bool(2), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'data_ref', 'id_cliente', 'sexo', 'posse_de_veiculo',\n",
      "       'posse_de_imovel', 'qtd_filhos', 'tipo_renda', 'educacao',\n",
      "       'estado_civil', 'tipo_residencia', 'idade', 'tempo_emprego',\n",
      "       'qt_pessoas_residencia', 'renda'],\n",
      "      dtype='object')\n",
      "Tamanho do conjunto de treinamento: 11250\n",
      "Tamanho do conjunto de teste: 3750\n"
     ]
    }
   ],
   "source": [
    "# Exibindo todas as colunas disponíveis no DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Criando variáveis dummy para colunas categóricas\n",
    "df_dummies = pd.get_dummies(df[['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia']], drop_first=True)\n",
    "\n",
    "# Concatenando as variáveis dummy com as colunas numéricas\n",
    "df = pd.concat([df[['posse_de_veiculo', 'posse_de_imovel', 'qtd_filhos', 'idade', 'tempo_emprego', 'qt_pessoas_residencia', 'renda']], df_dummies], axis=1)\n",
    "\n",
    "X = df.drop('renda', axis=1)\n",
    "y = df['renda']\n",
    "\n",
    "# Separando os dados em treinamento e teste (75% para treinamento, 25% para teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Imprimindo o tamanho dos conjuntos de treinamento e teste\n",
    "print(\"Tamanho do conjunto de treinamento:\", len(X_train))\n",
    "print(\"Tamanho do conjunto de teste:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 para diferentes valores de alpha: {0: 0.2691159056847583, 0.001: 0.2691159145559313, 0.005: 0.2691159500045429, 0.01: 0.26911599423430155, 0.05: 0.2691163448655334, 0.1: 0.26911677529614875}\n",
      "Melhor modelo - Alpha: 0.1, R^2: 0.26911677529614875\n"
     ]
    }
   ],
   "source": [
    "# Imputando valores ausentes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Inicializando listas para armazenar os resultados\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "r2_scores = []\n",
    "\n",
    "# Iterar sobre os valores de alpha\n",
    "for alpha in alphas:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train_imputed, y_train)\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "# Encontrando o melhor modelo (maior R^2)\n",
    "best_alpha = alphas[r2_scores.index(max(r2_scores))]\n",
    "best_r2 = max(r2_scores)\n",
    "\n",
    "# Imprimindo os resultados\n",
    "print(f\"R^2 para diferentes valores de alpha: {dict(zip(alphas, r2_scores))}\")\n",
    "print(f\"Melhor modelo - Alpha: {best_alpha}, R^2: {best_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando o R2, que mede a proporção da variabilidade na variável dependente que é explicada pelas variáveis independentes no modelo está mais próxima de 1, temos esse modelo como sendo melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo LASSO (R2 = 0.26525661212275686): Lasso(alpha=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e+11, tolerance: 7.723e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Imputando valores NaN\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['posse_de_imovel', 'idade', 'tempo_emprego', 'qt_pessoas_residencia', 'sexo_M', 'tipo_renda_Empresário', 'educacao_Superior completo']] = imputer.fit_transform(df[['posse_de_imovel', 'idade', 'tempo_emprego', 'qt_pessoas_residencia', 'sexo_M', 'tipo_renda_Empresário', 'educacao_Superior completo']])\n",
    "\n",
    "# Separando os dados em treinamento e teste (75% para treinamento, 25% para teste)\n",
    "X = df[['posse_de_imovel', 'idade', 'tempo_emprego', 'qt_pessoas_residencia', 'sexo_M', 'tipo_renda_Empresário', 'educacao_Superior completo']]\n",
    "y = df['renda']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Regressão LASSO\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "best_model_lasso = None\n",
    "best_r2_lasso = -float('inf')\n",
    "\n",
    "for alpha in alphas:\n",
    "    # Criar e treinar o modelo LASSO\n",
    "    model = Lasso(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Fazendo previsões no conjunto de testes\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Avaliando o desempenho usando R2\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Atualizando o melhor modelo se necessário\n",
    "    if r2 > best_r2_lasso:\n",
    "        best_r2_lasso = r2\n",
    "        best_model_lasso = model\n",
    "\n",
    "print(f\"Melhor modelo LASSO (R2 = {best_r2_lasso}): {best_model_lasso}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis selecionadas (forward): ['tempo_emprego', 'sexo_M', 'tipo_renda_Empresário', 'educacao_Superior completo']\n",
      "R2 do modelo (forward): 0.26361736232790967\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  renda   R-squared:                       0.256\n",
      "Model:                            OLS   Adj. R-squared:                  0.256\n",
      "Method:                 Least Squares   F-statistic:                     967.0\n",
      "Date:                Wed, 31 Jan 2024   Prob (F-statistic):               0.00\n",
      "Time:                        17:15:27   Log-Likelihood:            -1.1580e+05\n",
      "No. Observations:               11250   AIC:                         2.316e+05\n",
      "Df Residuals:                   11245   BIC:                         2.316e+05\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "const                      -1145.1115    138.973     -8.240      0.000   -1417.523    -872.700\n",
      "tempo_emprego                569.7288     11.094     51.354      0.000     547.982     591.475\n",
      "sexo_M                      5907.9108    145.213     40.684      0.000    5623.267    6192.555\n",
      "tipo_renda_Empresário        989.3660    160.532      6.163      0.000     674.696    1304.036\n",
      "educacao_Superior completo   681.4575    141.645      4.811      0.000     403.808     959.107\n",
      "==============================================================================\n",
      "Omnibus:                    16809.583   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         13458732.413\n",
      "Skew:                           8.946   Prob(JB):                         0.00\n",
      "Kurtosis:                     171.499   Cond. No.                         26.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def forward_selection(X, y, significance_level=0.05):\n",
    "    included = []\n",
    "    while True:\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(X[included + [new_column]])).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "\n",
    "        min_p_value = new_pval.min()\n",
    "        if min_p_value < significance_level:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return included\n",
    "\n",
    "# Realizando seleção de variáveis forward\n",
    "selected_features_forward = forward_selection(X_train, y_train)\n",
    "\n",
    "# Treinando o modelo com as variáveis selecionadas\n",
    "X_train_forward = X_train[selected_features_forward]\n",
    "model_forward = sm.OLS(y_train, sm.add_constant(X_train_forward)).fit()\n",
    "\n",
    "# Fazendo previsões no conjunto de testes\n",
    "X_test_forward = X_test[selected_features_forward]\n",
    "y_pred_forward = model_forward.predict(sm.add_constant(X_test_forward))\n",
    "\n",
    "# Avaliando o desempenho usando R2\n",
    "r2_forward = r2_score(y_test, y_pred_forward)\n",
    "\n",
    "print(f\"Variáveis selecionadas (forward): {selected_features_forward}\")\n",
    "print(f\"R2 do modelo (forward): {r2_forward}\")\n",
    "print(model_forward.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhor modelo LASSO (R2 = 0.26525661212275686). Inclusive, até o momento o modelo LASSO é o melhor de todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 do modelo de árvore de decisão: 0.30476532010427015\n"
     ]
    }
   ],
   "source": [
    "# Criar e treinar uma árvore de decisão\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de testes\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho usando R²\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"R2 do modelo de árvore de decisão: {r2_tree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Verifica-se uma melhora sensível no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
